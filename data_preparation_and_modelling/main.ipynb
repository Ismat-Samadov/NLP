{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1479c2ef-5df8-41d9-9347-8515157629a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2a185b60-b5af-4b3e-8ec8-8ca1afbba51d",
   "metadata": {},
   "source": [
    "## preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f6ca053b-7353-42ba-9134-c99f55bcedeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "data_1 = pd.read_csv('bina_az_02102023.csv')\n",
    "data_2 = pd.read_csv('bina_az_new.csv')\n",
    "data_3 = pd.read_csv('bina_az_old.csv')\n",
    "data_4 = pd.read_csv('bina_az_25102023.csv')\n",
    "data_5 = pd.read_csv('bina_az_01112023.csv')\n",
    "frames = pd.concat([data_1, data_2, data_3,data_4,data_5]).drop_duplicates().dropna()\n",
    "frames['is_near_metro'] = (frames['description'].str.contains('m\\.', case=False) | frames['description'].str.contains('metro',case=False)).astype(int)\n",
    "frames = frames[frames['seller_type'] != 'seller_type']\n",
    "frames[['flat', 'total_flat']] = frames['flat_number'].str.split(' / ', expand=True).astype(int)\n",
    "remove_non_numeric_and_convert_to_float = lambda value: float(re.sub(r'[^\\d.]', '', value)) if value else None\n",
    "frames['area_converted'] = frames['area'].apply(remove_non_numeric_and_convert_to_float)\n",
    "frames['room_count'] = frames['room_count'].astype(int)\n",
    "frames['documents_encoded'] = frames['documents'].map({'var': 1, 'yoxdur': 0})\n",
    "frames['is_repair_encoded'] = frames['is_repair'].map({'var': 1, 'yoxdur': 0})\n",
    "frames['seller_type_encoded'] = frames['seller_type'].map({'vasitəçi (agent)': 0, 'mülkiyyətçi': 1})\n",
    "frames['category_encoded'] = frames['category'].map({'Yeni tikili': 0, 'Köhnə tikili': 1})\n",
    "frames['price'] = frames['price'].str.replace(' ', '').astype(int)\n",
    "frames = frames[frames['price']>5000]\n",
    "frames = frames[['is_near_metro', \n",
    "                 'seller_type_encoded', \n",
    "                 'flat', \n",
    "                 'total_flat', \n",
    "                 'room_count',\n",
    "                 'area_converted', \n",
    "                 'category_encoded',\n",
    "                 'documents_encoded',\n",
    "                 'is_repair_encoded', \n",
    "                 'price']].drop_duplicates(ignore_index=True)\n",
    "# frames.to_excel('frames.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5be905a-638c-4bce-a4ab-66849a3c8ec2",
   "metadata": {},
   "source": [
    "## LazyPredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "435785ab-251d-4e57-8661-980ad9f9b26f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [12:20<00:00, 17.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001908 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 342\n",
      "[LightGBM] [Info] Number of data points in the train set: 25904, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 213771.250811\n",
      "(                               Adjusted R-Squared    R-Squared          RMSE  \\\n",
      "Model                                                                          \n",
      "BaggingRegressor                             0.75         0.75      80327.49   \n",
      "GradientBoostingRegressor                    0.74         0.74      80903.68   \n",
      "HistGradientBoostingRegressor                0.72         0.72      84550.07   \n",
      "XGBRegressor                                 0.72         0.72      84958.09   \n",
      "RandomForestRegressor                        0.71         0.71      85772.87   \n",
      "LGBMRegressor                                0.68         0.68      90077.37   \n",
      "RANSACRegressor                              0.65         0.65      94421.62   \n",
      "HuberRegressor                               0.64         0.64      95152.91   \n",
      "ExtraTreesRegressor                          0.61         0.61      99511.65   \n",
      "KNeighborsRegressor                          0.58         0.58     103837.86   \n",
      "PassiveAggressiveRegressor                   0.49         0.49     113335.98   \n",
      "PoissonRegressor                             0.42         0.42     121325.59   \n",
      "BayesianRidge                                0.42         0.42     121634.30   \n",
      "RidgeCV                                      0.42         0.42     121636.26   \n",
      "Ridge                                        0.42         0.42     121638.66   \n",
      "Lasso                                        0.42         0.42     121638.89   \n",
      "LassoLars                                    0.42         0.42     121638.89   \n",
      "LinearRegression                             0.42         0.42     121638.93   \n",
      "TransformedTargetRegressor                   0.42         0.42     121638.93   \n",
      "LassoLarsIC                                  0.42         0.42     121638.93   \n",
      "Lars                                         0.42         0.42     121638.93   \n",
      "OrthogonalMatchingPursuitCV                  0.41         0.42     121919.43   \n",
      "LarsCV                                       0.41         0.41     122025.36   \n",
      "LassoLarsCV                                  0.41         0.41     122025.36   \n",
      "LassoCV                                      0.41         0.41     122048.07   \n",
      "ElasticNet                                   0.39         0.40     123931.55   \n",
      "GammaRegressor                               0.36         0.36     127175.75   \n",
      "TweedieRegressor                             0.35         0.35     128438.87   \n",
      "OrthogonalMatchingPursuit                    0.34         0.34     129278.45   \n",
      "ElasticNetCV                                 0.01         0.01     158417.19   \n",
      "DummyRegressor                              -0.00        -0.00     159424.82   \n",
      "NuSVR                                       -0.02        -0.01     160602.07   \n",
      "SVR                                         -0.06        -0.06     164200.85   \n",
      "MLPRegressor                                -0.07        -0.07     165101.54   \n",
      "ExtraTreeRegressor                          -0.16        -0.16     171703.31   \n",
      "AdaBoostRegressor                           -0.27        -0.27     179436.91   \n",
      "DecisionTreeRegressor                       -0.84        -0.84     216350.65   \n",
      "LinearSVR                                   -1.37        -1.36     245019.28   \n",
      "KernelRidge                                 -1.38        -1.37     245573.57   \n",
      "GaussianProcessRegressor                 -1203.12     -1201.44    5527909.12   \n",
      "SGDRegressor                         -50911811.67 -50841046.21 1136673574.49   \n",
      "\n",
      "                               Time Taken  \n",
      "Model                                      \n",
      "BaggingRegressor                     0.86  \n",
      "GradientBoostingRegressor            2.12  \n",
      "HistGradientBoostingRegressor        0.47  \n",
      "XGBRegressor                         0.40  \n",
      "RandomForestRegressor               12.42  \n",
      "LGBMRegressor                        0.24  \n",
      "RANSACRegressor                      0.21  \n",
      "HuberRegressor                       0.30  \n",
      "ExtraTreesRegressor                  5.47  \n",
      "KNeighborsRegressor                  0.50  \n",
      "PassiveAggressiveRegressor           3.59  \n",
      "PoissonRegressor                     0.06  \n",
      "BayesianRidge                        0.04  \n",
      "RidgeCV                              0.05  \n",
      "Ridge                                0.03  \n",
      "Lasso                                0.10  \n",
      "LassoLars                            0.03  \n",
      "LinearRegression                     0.03  \n",
      "TransformedTargetRegressor           0.03  \n",
      "LassoLarsIC                          0.05  \n",
      "Lars                                 0.09  \n",
      "OrthogonalMatchingPursuitCV          0.13  \n",
      "LarsCV                               0.14  \n",
      "LassoLarsCV                          0.10  \n",
      "LassoCV                              0.37  \n",
      "ElasticNet                           0.04  \n",
      "GammaRegressor                       0.12  \n",
      "TweedieRegressor                     0.02  \n",
      "OrthogonalMatchingPursuit            0.05  \n",
      "ElasticNetCV                         0.22  \n",
      "DummyRegressor                       0.02  \n",
      "NuSVR                               51.44  \n",
      "SVR                                 48.16  \n",
      "MLPRegressor                        17.52  \n",
      "ExtraTreeRegressor                   0.07  \n",
      "AdaBoostRegressor                    0.79  \n",
      "DecisionTreeRegressor                0.15  \n",
      "LinearSVR                            0.05  \n",
      "KernelRidge                        246.15  \n",
      "GaussianProcessRegressor           347.38  \n",
      "SGDRegressor                         0.05  ,       AdaBoostRegressor  BaggingRegressor  BayesianRidge  \\\n",
      "0             380701.37         122300.00      185999.85   \n",
      "1             332726.72         111300.00      249850.24   \n",
      "2             356908.02         167150.00      154268.07   \n",
      "3             391442.53         307850.00      272241.53   \n",
      "4             332726.72         188807.51      181804.37   \n",
      "...                 ...               ...            ...   \n",
      "6471          332726.72         163792.22      179863.37   \n",
      "6472          332726.72         137839.74      179871.08   \n",
      "6473          332726.72          90916.67       79005.49   \n",
      "6474          278621.37         172500.00      277163.91   \n",
      "6475          816309.11         628100.00      385137.51   \n",
      "\n",
      "      DecisionTreeRegressor  DummyRegressor  ElasticNet  ElasticNetCV  \\\n",
      "0                 150000.00       213771.25   201281.55     214067.56   \n",
      "1                  83000.00       213771.25   226060.83     213548.42   \n",
      "2                 170000.00       213771.25   176177.85     213624.93   \n",
      "3                 277000.00       213771.25   261808.26     215060.45   \n",
      "4                 197181.82       213771.25   180017.02     212360.89   \n",
      "...                     ...             ...         ...           ...   \n",
      "6471              170000.00       213771.25   182750.49     212572.71   \n",
      "6472              135368.75       213771.25   182757.82     212572.89   \n",
      "6473               92000.00       213771.25   114789.72     211522.84   \n",
      "6474              183500.00       213771.25   265773.14     215357.07   \n",
      "6475              310000.00       213771.25   350391.77     217174.22   \n",
      "\n",
      "      ExtraTreeRegressor  ExtraTreesRegressor  GammaRegressor  ...  \\\n",
      "0              105000.00            116440.00       197909.20  ...   \n",
      "1               83000.00             83000.00       199556.83  ...   \n",
      "2              170000.00            175040.00       183064.30  ...   \n",
      "3              277000.00            277000.00       234236.73  ...   \n",
      "4              197181.82            197181.82       166219.34  ...   \n",
      "...                  ...                  ...             ...  ...   \n",
      "6471           170000.00            170000.00       168739.33  ...   \n",
      "6472           135368.75            135368.75       168744.76  ...   \n",
      "6473            92000.00             92000.00       138976.43  ...   \n",
      "6474           185000.00            184895.00       238020.39  ...   \n",
      "6475           900000.00            411901.00       309027.22  ...   \n",
      "\n",
      "      RANSACRegressor  RandomForestRegressor     Ridge   RidgeCV  \\\n",
      "0           129239.74              122285.00 185967.61 185985.33   \n",
      "1           161820.85               95250.00 249920.46 249881.84   \n",
      "2           184723.19              173599.33 154226.98 154249.57   \n",
      "3           240781.86              286378.83 272259.66 272249.69   \n",
      "4           157517.50              200094.82 181811.82 181807.73   \n",
      "...               ...                    ...       ...       ...   \n",
      "6471        130690.82              160589.99 179858.31 179861.09   \n",
      "6472        132305.99              135327.19 179866.02 179868.80   \n",
      "6473         75862.13               91518.25  78937.87  78975.03   \n",
      "6474        231154.01              186185.00 277182.12 277172.11   \n",
      "6475        421995.83              577841.96 385185.86 385159.30   \n",
      "\n",
      "       SGDRegressor       SVR  TransformedTargetRegressor  TweedieRegressor  \\\n",
      "0    -1138001668.06 171017.73                   185965.64         207891.26   \n",
      "1    -1120109058.21 169700.01                   249924.75         219152.82   \n",
      "2      178813287.59 170447.89                   154224.47         187696.69   \n",
      "3     -134271501.29 171862.17                   272260.76         254537.61   \n",
      "4      -74979786.90 167890.57                   181812.28         181651.49   \n",
      "...             ...       ...                         ...               ...   \n",
      "6471  -674635278.18 167970.58                   179858.00         185310.70   \n",
      "6472  -639328555.38 167970.68                   179865.71         185317.07   \n",
      "6473  -146919680.01 167221.83                    78933.74         133897.32   \n",
      "6474 -1181688135.52 171208.35                   277183.23         258411.18   \n",
      "6475  1007828240.27 171369.06                   385188.81         327087.57   \n",
      "\n",
      "      XGBRegressor  LGBMRegressor  \n",
      "0        121423.48      128937.96  \n",
      "1        128104.35      140405.12  \n",
      "2        177068.45      172064.48  \n",
      "3        263840.97      264651.27  \n",
      "4        169934.39      165543.40  \n",
      "...            ...            ...  \n",
      "6471     132660.69      131904.14  \n",
      "6472     132660.69      131904.14  \n",
      "6473      89424.64       90129.63  \n",
      "6474     210457.83      205344.09  \n",
      "6475     604955.25      472262.88  \n",
      "\n",
      "[6476 rows x 41 columns])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from lazypredict.Supervised import LazyRegressor\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "data = frames\n",
    "X = data.drop(columns=['price'])\n",
    "y = data['price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "reg = LazyRegressor(predictions=True)\n",
    "models = reg.fit(X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "print(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97be3987-25a0-4bbc-a4bf-df064ab6231f",
   "metadata": {},
   "source": [
    "## Grid Search for BaggingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "57498d78-2340-4719-9622-b83037141984",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:\n",
      "{'base_estimator': None, 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 400}\n",
      "Model performance metrics\n",
      "-----------------------\n",
      "R-squared: 0.72\n",
      "Root Mean Squared Error: 84893.56\n",
      "Mean Absolute Error: 39863.24\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor \n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "data = frames\n",
    "X = data.drop(columns=['price'])\n",
    "y = data['price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "bagging_regressor = BaggingRegressor()\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300 ,400 , 500 ,],  \n",
    "    'base_estimator': [None , DecisionTreeRegressor()],  \n",
    "    'max_samples': [1.0], \n",
    "    'max_features': [1.0], \n",
    "}\n",
    "grid_search = GridSearchCV(bagging_regressor, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "best_params = grid_search.best_params_\n",
    "best_estimator = grid_search.best_estimator_\n",
    "print(\"Best Hyperparameters:\")\n",
    "print(best_params)\n",
    "y_pred = best_estimator.predict(X_test_scaled)\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(\"Model performance metrics\")\n",
    "print(\"-----------------------\")\n",
    "print(f\"R-squared: {r2:.2f}\")\n",
    "print(f\"Root Mean Squared Error: {rmse:.2f}\")\n",
    "print(f\"Mean Absolute Error: {mae:.2f}\")\n",
    "print(\"-----------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c90938-703f-4f17-8a94-d72e908bc271",
   "metadata": {},
   "source": [
    "## BaggingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "89a324ec-a607-4b80-a79f-192a2ede566a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model performance metrics\n",
      "-----------------------\n",
      "R-squared: 0.72\n",
      "Root Mean Squared Error: 84239.68\n",
      "Mean Absolute Error: 39887.55\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "data = frames\n",
    "X = data.drop(columns=['price'])\n",
    "y = data['price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "best_bagging_regressor = BaggingRegressor(\n",
    "    base_estimator=None,\n",
    "    n_estimators=400,\n",
    "    max_samples=1.0,\n",
    "    max_features=1.0\n",
    ")\n",
    "best_bagging_regressor.fit(X_train_scaled, y_train)\n",
    "y_pred = best_bagging_regressor.predict(X_test_scaled)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(\"Model performance metrics\")\n",
    "print(\"-----------------------\")\n",
    "print(f\"R-squared: {r2:.2f}\")\n",
    "print(f\"Root Mean Squared Error: {rmse:.2f}\")\n",
    "print(f\"Mean Absolute Error: {mae:.2f}\")\n",
    "print(\"-----------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bab8c81-2309-437e-bb7f-dea72c954a05",
   "metadata": {},
   "source": [
    "## RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "413b3058-d9a2-4358-8b56-e2793a456f50",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model performance metrics\n",
      "-----------------------\n",
      "R-squared: 0.76\n",
      "Root Mean Squared Error: 78613.17\n",
      "Mean Absolute Error: 39946.44\n",
      "-----------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['random_forest.pkl']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "data = frames\n",
    "X = data.drop(columns=['price'])\n",
    "y = data['price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "model = RandomForestRegressor(\n",
    "    n_estimators=300,  \n",
    "    max_depth=50,  \n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=4, \n",
    "    random_state=42 \n",
    ")\n",
    "\n",
    "model.fit(X_train_scaled, y_train)\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(\"Model performance metrics\")\n",
    "print(\"-----------------------\")\n",
    "print(f\"R-squared: {r2:.2f}\")\n",
    "print(f\"Root Mean Squared Error: {rmse:.2f}\")\n",
    "print(f\"Mean Absolute Error: {mae:.2f}\")\n",
    "print(\"-----------------------\")\n",
    "joblib.dump(model, 'random_forest.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f655ca2b-39ad-4551-9335-942d1912d9f8",
   "metadata": {},
   "source": [
    "## XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "07527bc7-f725-48c2-af57-5d26ef3b25e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model performance metrics\n",
      "-----------------------\n",
      "R-squared: 0.71\n",
      "Root Mean Squared Error: 85155.23\n",
      "Mean Absolute Error: 44965.97\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "data = frames\n",
    "X = data.drop(columns=['price'])\n",
    "y = data['price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "model = xgb.XGBRegressor(\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=100,\n",
    "    max_depth=3,\n",
    "    objective='reg:squarederror'\n",
    ")\n",
    "model.fit(X_train_scaled, y_train)\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(\"Model performance metrics\")\n",
    "print(\"-----------------------\")\n",
    "print(f\"R-squared: {r2:.2f}\")\n",
    "print(f\"Root Mean Squared Error: {rmse:.2f}\")\n",
    "print(f\"Mean Absolute Error: {mae:.2f}\")\n",
    "print(\"-----------------------\")\n",
    "# joblib.dump(model, 'xgb.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0e47c6-f40a-49bf-ba7c-b14636ee532e",
   "metadata": {},
   "source": [
    "## Grid Search RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "239384cd-3467-4f57-911a-450a4eab63a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'max_depth': 30, 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "R-squared: 0.738799711229776\n",
      "Root Mean Squared Error (RMSE): 89502.17958782492\n",
      "Mean Absolute Error (MAE): 42727.429187055845\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "data = frames\n",
    "X = data.drop(columns=['price'])\n",
    "y = data['price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "rf_model = RandomForestRegressor()\n",
    "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, scoring='neg_mean_squared_error', cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "predictions = best_model.predict(X_test)\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "r_squared = r2_score(y_test, predictions)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "print(\"R-squared:\", r_squared)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcede46c-cb58-43f1-b985-f2a7ad116256",
   "metadata": {},
   "source": [
    "## Grid search for XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80984780-b2a0-4057-9425-c18a4f0026fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100, 'subsample': 0.9}\n",
      "R-squared: 0.7077243215163627\n",
      "Root Mean Squared Error (RMSE): 94676.70258377517\n",
      "Mean Absolute Error (MAE): 47888.042196584305\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "data = frames\n",
    "X = data.drop(columns=['price'])\n",
    "y = data['price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 4, 5],  \n",
    "    'learning_rate': [0.01, 0.1, 0.2],  \n",
    "    'subsample': [0.8, 0.9, 1.0], \n",
    "}\n",
    "xgb_model = XGBRegressor()  \n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, scoring='neg_mean_squared_error', cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "predictions = best_model.predict(X_test)\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "r_squared = r2_score(y_test, predictions)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "print(\"R-squared:\", r_squared)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5642a81d-6999-4887-92c3-4fe01e37e415",
   "metadata": {},
   "source": [
    "## Ensemble methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81e0ec6b-9687-4c82-a27a-0a09a465e60f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Model Performance Metrics\n",
      "-----------------------\n",
      "R-squared: 0.75\n",
      "Root Mean Squared Error: 88404.88\n",
      "Mean Absolute Error: 43143.62\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "data = frames\n",
    "X = data.drop(columns=['price'])\n",
    "y = data['price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "xgb_model = xgb.XGBRegressor(\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=100,\n",
    "    max_depth=3,\n",
    "    objective='reg:squarederror'\n",
    ")\n",
    "xgb_model.fit(X_train_scaled, y_train)\n",
    "rf_predictions = rf_model.predict(X_test_scaled)\n",
    "xgb_predictions = xgb_model.predict(X_test_scaled)\n",
    "ensemble_predictions = (rf_predictions + xgb_predictions) / 2\n",
    "ensemble_r2 = r2_score(y_test, ensemble_predictions)\n",
    "ensemble_rmse = mean_squared_error(y_test, ensemble_predictions, squared=False)\n",
    "ensemble_mae = mean_absolute_error(y_test, ensemble_predictions)\n",
    "print(\"Ensemble Model Performance Metrics\")\n",
    "print(\"-----------------------\")\n",
    "print(f\"R-squared: {ensemble_r2:.2f}\")\n",
    "print(f\"Root Mean Squared Error: {ensemble_rmse:.2f}\")\n",
    "print(f\"Mean Absolute Error: {ensemble_mae:.2f}\")\n",
    "print(\"-----------------------\")\n",
    "# joblib.dump(rf_model, 'random_forest.pkl')\n",
    "# joblib.dump(xgb_model, 'xgboost.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1be878a-b204-4940-bf44-5496397d970d",
   "metadata": {},
   "source": [
    "## Stacking method for ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97593f47-b08c-4924-8665-3aeaa9f7d02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Model Performance Metrics\n",
      "-----------------------\n",
      "R-squared: 0.75\n",
      "Root Mean Squared Error: 87161.80\n",
      "Mean Absolute Error: 41856.48\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "xgb_model = XGBRegressor(learning_rate=0.1, n_estimators=100, max_depth=3, objective='reg:squarederror')\n",
    "gb_model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "gb_model.fit(X_train, y_train)\n",
    "rf_predictions = rf_model.predict(X_val)\n",
    "xgb_predictions = xgb_model.predict(X_val)\n",
    "gb_predictions = gb_model.predict(X_val)\n",
    "meta_model = LinearRegression()\n",
    "meta_features = pd.DataFrame({'RandomForest': rf_predictions, 'XGBoost': xgb_predictions, 'GradientBoosting': gb_predictions})\n",
    "meta_model.fit(meta_features, y_val)\n",
    "rf_test_predictions = rf_model.predict(X_test)\n",
    "xgb_test_predictions = xgb_model.predict(X_test)\n",
    "gb_test_predictions = gb_model.predict(X_test)\n",
    "meta_test_features = pd.DataFrame({'RandomForest': rf_test_predictions, 'XGBoost': xgb_test_predictions, 'GradientBoosting': gb_test_predictions})\n",
    "final_predictions = meta_model.predict(meta_test_features)\n",
    "ensemble_r2 = r2_score(y_test, final_predictions)\n",
    "ensemble_rmse = mean_squared_error(y_test, final_predictions, squared=False)\n",
    "ensemble_mae = mean_absolute_error(y_test, final_predictions)\n",
    "print(\"Ensemble Model Performance Metrics\")\n",
    "print(\"-----------------------\")\n",
    "print(f\"R-squared: {ensemble_r2:.2f}\")\n",
    "print(f\"Root Mean Squared Error: {ensemble_rmse:.2f}\")\n",
    "print(f\"Mean Absolute Error: {ensemble_mae:.2f}\")\n",
    "print(\"-----------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8adeb377-2c0e-4cbe-8106-05857b8eebb5",
   "metadata": {},
   "source": [
    "## Blending method for ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b8501ea-4f76-465e-9520-9cfba9863b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Model Performance Metrics\n",
      "-----------------------\n",
      "R-squared: 0.74\n",
      "Root Mean Squared Error: 88480.09\n",
      "Mean Absolute Error: 42442.15\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "X_base_train, X_meta_train, y_base_train, y_meta_train = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "rf_model.fit(X_base_train, y_base_train)\n",
    "xgb_model.fit(X_base_train, y_base_train)\n",
    "gb_model.fit(X_base_train, y_base_train)\n",
    "rf_meta_predictions = rf_model.predict(X_meta_train)\n",
    "xgb_meta_predictions = xgb_model.predict(X_meta_train)\n",
    "gb_meta_predictions = gb_model.predict(X_meta_train)\n",
    "meta_features = pd.DataFrame({'RandomForest': rf_meta_predictions, 'XGBoost': xgb_meta_predictions, 'GradientBoosting': gb_meta_predictions})\n",
    "meta_model.fit(meta_features, y_meta_train)\n",
    "rf_test_predictions = rf_model.predict(X_test)\n",
    "xgb_test_predictions = xgb_model.predict(X_test)\n",
    "gb_test_predictions = gb_model.predict(X_test)\n",
    "meta_test_features = pd.DataFrame({'RandomForest': rf_test_predictions, 'XGBoost': xgb_test_predictions, 'GradientBoosting': gb_test_predictions})\n",
    "final_predictions = meta_model.predict(meta_test_features)\n",
    "ensemble_r2 = r2_score(y_test, final_predictions)\n",
    "ensemble_rmse = mean_squared_error(y_test, final_predictions, squared=False)\n",
    "ensemble_mae = mean_absolute_error(y_test, final_predictions)\n",
    "print(\"Ensemble Model Performance Metrics\")\n",
    "print(\"-----------------------\")\n",
    "print(f\"R-squared: {ensemble_r2:.2f}\")\n",
    "print(f\"Root Mean Squared Error: {ensemble_rmse:.2f}\")\n",
    "print(f\"Mean Absolute Error: {ensemble_mae:.2f}\")\n",
    "print(\"-----------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef340b6-b678-4b09-a35d-7c7fb296a4ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9f83d310-90e6-48b0-8088-dbc51a4582fb",
   "metadata": {},
   "source": [
    "## neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d20addb-8bb9-4998-af50-223421c08d23",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 2ms/step\n",
      "Neural Network Performance Metrics\n",
      "-----------------------\n",
      "R-squared: 0.49\n",
      "Root Mean Squared Error: 125015.13\n",
      "Mean Absolute Error: 67906.16\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "data = frames\n",
    "X = data.drop(columns=['price'])\n",
    "y = data['price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "model = keras.Sequential([\n",
    "    layers.Input(shape=(X_train_scaled.shape[1],)), \n",
    "    layers.Dense(128, activation='relu'),  \n",
    "    layers.Dense(64, activation='relu'),   \n",
    "    layers.Dense(1) \n",
    "])\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, verbose=0)\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(\"Neural Network Performance Metrics\")\n",
    "print(\"-----------------------\")\n",
    "print(f\"R-squared: {r2:.2f}\")\n",
    "print(f\"Root Mean Squared Error: {rmse:.2f}\")\n",
    "print(f\"Mean Absolute Error: {mae:.2f}\")\n",
    "print(\"-----------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3a01fae9-06a7-4150-b138-e1f7c4e6a150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 1ms/step\n",
      "Improved Neural Network Performance Metrics\n",
      "-----------------------\n",
      "R-squared: 0.45\n",
      "Root Mean Squared Error: 129786.08\n",
      "Mean Absolute Error: 79261.65\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "data = frames\n",
    "X = data.drop(columns=['price'])\n",
    "y = data['price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "model = keras.Sequential([\n",
    "    layers.Input(shape=(X_train_scaled.shape[1],)),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=0.01,\n",
    "    decay_steps=1000,\n",
    "    decay_rate=0.9\n",
    ")\n",
    "optimizer = keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "def custom_loss(y_true, y_pred):\n",
    "    return keras.losses.mean_squared_error(y_true, y_pred) + 0.01 * keras.losses.kl_divergence(y_true, y_pred)\n",
    "model.compile(optimizer=optimizer, loss=custom_loss, metrics=['mae'])\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "history = model.fit(\n",
    "    X_train_scaled, y_train, \n",
    "    epochs=150, \n",
    "    batch_size=64, \n",
    "    validation_data=(X_test_scaled, y_test), \n",
    "    verbose=0, \n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(\"Improved Neural Network Performance Metrics\")\n",
    "print(\"-----------------------\")\n",
    "print(f\"R-squared: {r2:.2f}\")\n",
    "print(f\"Root Mean Squared Error: {rmse:.2f}\")\n",
    "print(f\"Mean Absolute Error: {mae:.2f}\")\n",
    "print(\"-----------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4eaa5ce3-c8b5-4ebe-a9e4-ebcf0b7a854d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 1ms/step\n",
      "Improved Neural Network Performance Metrics\n",
      "-----------------------\n",
      "R-squared: 0.59\n",
      "Root Mean Squared Error: 111911.90\n",
      "Mean Absolute Error: 60077.42\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "data = frames\n",
    "X = data.drop(columns=['price'])\n",
    "y = data['price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "model = keras.Sequential([\n",
    "    layers.Input(shape=(X_train_scaled.shape[1],)),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "initial_learning_rate = 0.01\n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate, decay_steps=1000, decay_rate=0.9, staircase=True\n",
    ")\n",
    "optimizer = keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "def custom_loss(y_true, y_pred):\n",
    "    mse = keras.losses.mean_squared_error(y_true, y_pred)\n",
    "    regularization = 0.01 * tf.reduce_sum(model.losses)\n",
    "    return mse + regularization\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=custom_loss, metrics=['mae'])\n",
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', patience=15, restore_best_weights=True\n",
    ")\n",
    "history = model.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    epochs=200,\n",
    "    batch_size=64,\n",
    "    validation_data=(X_test_scaled, y_test),\n",
    "    verbose=0,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(\"Improved Neural Network Performance Metrics\")\n",
    "print(\"-----------------------\")\n",
    "print(f\"R-squared: {r2:.2f}\")\n",
    "print(f\"Root Mean Squared Error: {rmse:.2f}\")\n",
    "print(f\"Mean Absolute Error: {mae:.2f}\")\n",
    "print(\"-----------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9b709a64-80e8-4199-a410-4e4c87f14eb4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 1ms/step\n",
      "178/178 [==============================] - 0s 2ms/step\n",
      "178/178 [==============================] - 0s 1ms/step\n",
      "178/178 [==============================] - 0s 2ms/step\n",
      "178/178 [==============================] - 0s 1ms/step\n",
      "Ensemble of Neural Networks Performance Metrics\n",
      "-----------------------\n",
      "R-squared: 0.62\n",
      "Root Mean Squared Error: 108341.71\n",
      "Mean Absolute Error: 59353.70\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "data = frames\n",
    "X = data.drop(columns=['price'])\n",
    "y = data['price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "num_networks = 5\n",
    "ensemble_predictions = []\n",
    "for i in range(num_networks):\n",
    "    model = keras.Sequential([\n",
    "        layers.Input(shape=(X_train_scaled.shape[1],)),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(32, activation='relu'),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "    initial_learning_rate = 0.01\n",
    "    lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate, decay_steps=1000, decay_rate=0.9, staircase=True\n",
    "    )\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "    def custom_loss(y_true, y_pred):\n",
    "        mse = keras.losses.mean_squared_error(y_true, y_pred)\n",
    "        regularization = 0.01 * tf.reduce_sum(model.losses)\n",
    "        return mse + regularization\n",
    "    model.compile(optimizer=optimizer, loss=custom_loss, metrics=['mae'])\n",
    "    early_stopping = keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss', patience=15, restore_best_weights=True\n",
    "    )\n",
    "    history = model.fit(\n",
    "        X_train_scaled, y_train,\n",
    "        epochs=200,\n",
    "        batch_size=64,\n",
    "        validation_data=(X_test_scaled, y_test),\n",
    "        verbose=0,\n",
    "        callbacks=[early_stopping]\n",
    "    )\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    ensemble_predictions.append(y_pred)\n",
    "ensemble_predictions = np.mean(ensemble_predictions, axis=0)\n",
    "r2 = r2_score(y_test, ensemble_predictions)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, ensemble_predictions))\n",
    "mae = mean_absolute_error(y_test, ensemble_predictions)\n",
    "print(\"Ensemble of Neural Networks Performance Metrics\")\n",
    "print(\"-----------------------\")\n",
    "print(f\"R-squared: {r2:.2f}\")\n",
    "print(f\"Root Mean Squared Error: {rmse:.2f}\")\n",
    "print(f\"Mean Absolute Error: {mae:.2f}\")\n",
    "print(\"-----------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "289bfca6-c11d-4283-a922-1ef1a5e900ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 1ms/step\n",
      "178/178 [==============================] - 0s 1ms/step\n",
      "178/178 [==============================] - 0s 1ms/step\n",
      "178/178 [==============================] - 0s 1ms/step\n",
      "178/178 [==============================] - 0s 2ms/step\n",
      "Ensemble of Neural Networks Performance Metrics\n",
      "-----------------------\n",
      "R-squared: 0.67\n",
      "Root Mean Squared Error: 100792.64\n",
      "Mean Absolute Error: 50511.93\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "data = frames\n",
    "X = data.drop(columns=['price'])\n",
    "y = data['price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "num_networks = 5\n",
    "ensemble_predictions = []\n",
    "for i in range(num_networks):\n",
    "    model = keras.Sequential([\n",
    "        layers.Input(shape=(X_train_scaled.shape[1],)),\n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(32, activation='relu'),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "    initial_learning_rate = 0.01\n",
    "    lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate, decay_steps=1000, decay_rate=0.9, staircase=True\n",
    "    )\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "    def custom_loss(y_true, y_pred):\n",
    "        mse = keras.losses.mean_squared_error(y_true, y_pred)\n",
    "        regularization = 0.01 * tf.reduce_sum(model.losses)\n",
    "        return mse + regularization\n",
    "    model.compile(optimizer=optimizer, loss=custom_loss, metrics=['mae'])\n",
    "    early_stopping = keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss', patience=15, restore_best_weights=True\n",
    "    )\n",
    "    history = model.fit(\n",
    "        X_train_scaled, y_train,\n",
    "        epochs=200,\n",
    "        batch_size=64,\n",
    "        validation_data=(X_test_scaled, y_test),\n",
    "        verbose=0,\n",
    "        callbacks=[early_stopping]\n",
    "    )\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    ensemble_predictions.append(y_pred)\n",
    "ensemble_predictions = np.mean(ensemble_predictions, axis=0)\n",
    "r2 = r2_score(y_test, ensemble_predictions)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, ensemble_predictions))\n",
    "mae = mean_absolute_error(y_test, ensemble_predictions)\n",
    "print(\"Ensemble of Neural Networks Performance Metrics\")\n",
    "print(\"-----------------------\")\n",
    "print(f\"R-squared: {r2:.2f}\")\n",
    "print(f\"Root Mean Squared Error: {rmse:.2f}\")\n",
    "print(f\"Mean Absolute Error: {mae:.2f}\")\n",
    "print(\"-----------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "18cbdd54-7626-4f95-a4c6-57028b6d201b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 2ms/step\n",
      "178/178 [==============================] - 0s 1ms/step\n",
      "178/178 [==============================] - 0s 1ms/step\n",
      "178/178 [==============================] - 0s 1ms/step\n",
      "178/178 [==============================] - 0s 1ms/step\n",
      "178/178 [==============================] - 0s 1ms/step\n",
      "178/178 [==============================] - 0s 2ms/step\n",
      "178/178 [==============================] - 0s 1ms/step\n",
      "178/178 [==============================] - 0s 2ms/step\n",
      "178/178 [==============================] - 0s 2ms/step\n",
      "178/178 [==============================] - 1s 2ms/step\n",
      "178/178 [==============================] - 0s 1ms/step\n",
      "178/178 [==============================] - 0s 1ms/step\n",
      "178/178 [==============================] - 0s 1ms/step\n",
      "178/178 [==============================] - 0s 1ms/step\n",
      "178/178 [==============================] - 0s 1ms/step\n",
      "178/178 [==============================] - 0s 1ms/step\n",
      "178/178 [==============================] - 0s 2ms/step\n",
      "178/178 [==============================] - 0s 1ms/step\n",
      "178/178 [==============================] - 0s 2ms/step\n",
      "Ensemble of Neural Networks Performance Metrics\n",
      "-----------------------\n",
      "R-squared: 0.68\n",
      "Root Mean Squared Error: 99066.72\n",
      "Mean Absolute Error: 48012.44\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "data = frames\n",
    "X = data.drop(columns=['price'])\n",
    "y = data['price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "num_networks = 20\n",
    "ensemble_predictions = []\n",
    "for i in range(num_networks):\n",
    "    model = keras.Sequential([\n",
    "        layers.Input(shape=(X_train_scaled.shape[1],)),\n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.Dropout(0.4),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(32, activation='relu'),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "    initial_learning_rate = 0.01\n",
    "    lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate, decay_steps=1000, decay_rate=0.9, staircase=True\n",
    "    )\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "    def custom_loss(y_true, y_pred):\n",
    "        mse = keras.losses.mean_squared_error(y_true, y_pred)\n",
    "        regularization = 0.01 * tf.reduce_sum(model.losses)\n",
    "        return mse + regularization\n",
    "    model.compile(optimizer=optimizer, loss=custom_loss, metrics=['mae'])\n",
    "    early_stopping = keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss', patience=20, restore_best_weights=True\n",
    "    )\n",
    "    history = model.fit(\n",
    "        X_train_scaled, y_train,\n",
    "        epochs=250,\n",
    "        batch_size=64,\n",
    "        validation_data=(X_test_scaled, y_test),\n",
    "        verbose=0,\n",
    "        callbacks=[early_stopping]\n",
    "    )\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    ensemble_predictions.append(y_pred)\n",
    "ensemble_predictions = np.mean(ensemble_predictions, axis=0)\n",
    "r2 = r2_score(y_test, ensemble_predictions)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, ensemble_predictions))\n",
    "mae = mean_absolute_error(y_test, ensemble_predictions)\n",
    "print(\"Ensemble of Neural Networks Performance Metrics\")\n",
    "print(\"-----------------------\")\n",
    "print(f\"R-squared: {r2:.2f}\")\n",
    "print(f\"Root Mean Squared Error: {rmse:.2f}\")\n",
    "print(f\"Mean Absolute Error: {mae:.2f}\")\n",
    "print(\"-----------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7c255e-c5e9-46b4-aea5-9eb04cab2de6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
